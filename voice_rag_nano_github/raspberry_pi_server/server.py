#!/usr/bin/env python3
"""
ğŸ–¥ï¸ Raspberry Pi 5 Voice RAG Server

ESP32ì—ì„œ ìŒì„±ì„ ë°›ì•„ AI ë‹µë³€ì„ ìƒì„±í•˜ê³  ìŒì„±ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

êµ¬ì„±:
- Flask: HTTP ì„œë²„
- Whisper: ìŒì„± ì¸ì‹ (STT)
- Ollama + RAG: AI ë‹µë³€ ìƒì„±
- Edge-TTS: ìŒì„± í•©ì„± (TTS)

ì‹¤í–‰:
    python server.py

í…ŒìŠ¤íŠ¸:
    curl http://localhost:5000/health
"""

import os
import io
import wave
import time
import logging
import tempfile
import asyncio
from pathlib import Path
from flask import Flask, request, jsonify, send_file
import numpy as np

# =====================================
# ğŸ“ ë¡œê¹… ì„¤ì •
# =====================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# =====================================
# âš™ï¸ ì„¤ì •
# =====================================
class Config:
    # ì„œë²„
    HOST = '0.0.0.0'
    PORT = 5000
    
    # ì˜¤ë””ì˜¤ (ESP32ì™€ ì¼ì¹˜)
    SAMPLE_RATE = 16000
    SAMPLE_WIDTH = 2  # 16-bit
    CHANNELS = 1
    
    # ê²½ë¡œ
    DOCUMENTS_DIR = Path('./documents')
    
    # Ollama
    OLLAMA_MODEL = 'llama3.2'
    OLLAMA_URL = 'http://localhost:11434'
    
    # Whisper
    WHISPER_MODEL = 'base'  # tiny, base, small, medium, large
    
    # TTS
    TTS_VOICE_KO = 'ko-KR-SunHiNeural'   # í•œêµ­ì–´ ì—¬ì„±
    TTS_VOICE_EN = 'en-US-JennyNeural'    # ì˜ì–´ ì—¬ì„±
    TTS_LANGUAGE = 'ko'  # ê¸°ë³¸ ì–¸ì–´

# =====================================
# ğŸŒ Flask ì•±
# =====================================
app = Flask(__name__)

# =====================================
# ğŸ¤ ìŒì„± ì¸ì‹ (Whisper)
# =====================================
class SpeechRecognizer:
    def __init__(self, model_name='base'):
        logger.info(f"Loading Whisper model: {model_name}")
        import whisper
        self.model = whisper.load_model(model_name)
        logger.info("Whisper model loaded!")
    
    def transcribe(self, audio_data: bytes) -> str:
        """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
            f.write(audio_data)
            temp_path = f.name
        
        try:
            result = self.model.transcribe(
                temp_path,
                language=Config.TTS_LANGUAGE,
                fp16=False  # Raspberry Piì—ì„œëŠ” fp32 ì‚¬ìš©
            )
            text = result['text'].strip()
            logger.info(f"STT: '{text}'")
            return text
        finally:
            os.unlink(temp_path)

# =====================================
# ğŸ”Š ìŒì„± í•©ì„± (Edge-TTS)
# =====================================
class SpeechSynthesizer:
    def __init__(self, language='ko'):
        self.language = language
        self.voice = Config.TTS_VOICE_KO if language == 'ko' else Config.TTS_VOICE_EN
        logger.info(f"TTS initialized: {self.voice}")
    
    async def _synthesize_async(self, text: str) -> bytes:
        """ë¹„ë™ê¸° ìŒì„± í•©ì„±"""
        import edge_tts
        
        communicate = edge_tts.Communicate(text, self.voice)
        audio_data = b""
        
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_data += chunk["data"]
        
        return audio_data
    
    def synthesize(self, text: str) -> bytes:
        """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ (WAV ë°˜í™˜)"""
        logger.info(f"TTS: '{text[:50]}...'")
        
        # ë¹„ë™ê¸° ì‹¤í–‰
        mp3_data = asyncio.run(self._synthesize_async(text))
        
        # MP3 â†’ WAV ë³€í™˜
        wav_data = self._mp3_to_wav(mp3_data)
        
        return wav_data
    
    def _mp3_to_wav(self, mp3_data: bytes) -> bytes:
        """MP3ë¥¼ WAVë¡œ ë³€í™˜"""
        from pydub import AudioSegment
        
        audio = AudioSegment.from_mp3(io.BytesIO(mp3_data))
        audio = audio.set_frame_rate(Config.SAMPLE_RATE)
        audio = audio.set_channels(Config.CHANNELS)
        audio = audio.set_sample_width(Config.SAMPLE_WIDTH)
        
        wav_buffer = io.BytesIO()
        audio.export(wav_buffer, format='wav')
        wav_buffer.seek(0)
        
        return wav_buffer.read()

# =====================================
# ğŸ¤– RAG ì—”ì§„
# =====================================
class RAGEngine:
    def __init__(self, docs_dir: Path, model: str, ollama_url: str):
        self.docs_dir = docs_dir
        self.model = model
        self.ollama_url = ollama_url
        
        self.documents = []
        self.embeddings = None
        self.embedding_model = None
        
        self._load_embedding_model()
        self._load_documents()
        
        logger.info(f"RAG Engine ready: {len(self.documents)} documents")
    
    def _load_embedding_model(self):
        """ì„ë² ë”© ëª¨ë¸ ë¡œë“œ"""
        from sentence_transformers import SentenceTransformer
        logger.info("Loading embedding model...")
        self.embedding_model = SentenceTransformer(
            'paraphrase-multilingual-MiniLM-L12-v2'
        )
    
    def _load_documents(self):
        """ë¬¸ì„œ ë¡œë“œ ë° ì¸ë±ì‹±"""
        self.docs_dir.mkdir(exist_ok=True)
        
        # ì§€ì› í™•ì¥ì
        extensions = ['.txt', '.md']
        
        for ext in extensions:
            for file_path in self.docs_dir.glob(f'**/*{ext}'):
                try:
                    content = file_path.read_text(encoding='utf-8')
                    chunks = self._chunk_text(content)
                    
                    for chunk in chunks:
                        self.documents.append({
                            'content': chunk,
                            'source': file_path.name
                        })
                    
                    logger.info(f"Loaded: {file_path.name} ({len(chunks)} chunks)")
                except Exception as e:
                    logger.error(f"Failed to load {file_path}: {e}")
        
        # ìƒ˜í”Œ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not self.documents:
            self._create_sample_doc()
        
        # ì„ë² ë”© ìƒì„±
        if self.documents:
            texts = [d['content'] for d in self.documents]
            self.embeddings = self.embedding_model.encode(texts)
            logger.info(f"Created {len(self.embeddings)} embeddings")
    
    def _chunk_text(self, text: str, chunk_size: int = 500) -> list:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            chunk = text[start:end]
            
            # ë¬¸ì¥ ê²½ê³„ì—ì„œ ìë¥´ê¸°
            if end < len(text):
                for sep in ['. ', '.\n', '\n\n', '\n']:
                    last = chunk.rfind(sep)
                    if last > chunk_size // 2:
                        chunk = text[start:start + last + len(sep)]
                        end = start + last + len(sep)
                        break
            
            if chunk.strip():
                chunks.append(chunk.strip())
            
            start = end
        
        return chunks
    
    def _create_sample_doc(self):
        """ìƒ˜í”Œ ë¬¸ì„œ ìƒì„±"""
        sample = self.docs_dir / 'guide.txt'
        sample.write_text('''# Voice RAG ì‹œìŠ¤í…œ ê°€ì´ë“œ

ì´ ì‹œìŠ¤í…œì€ ìŒì„±ìœ¼ë¡œ ì§ˆë¬¸í•˜ë©´ AIê°€ ë‹µë³€í•´ì£¼ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ì‚¬ìš© ë°©ë²•
1. ESP32ì˜ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”
2. ë§ˆì´í¬ì— ëŒ€ê³  ì§ˆë¬¸í•˜ì„¸ìš”
3. ë²„íŠ¼ì„ ë†“ìœ¼ë©´ AIê°€ ë‹µë³€í•©ë‹ˆë‹¤

## ê¸°ëŠ¥
- ìŒì„± ì¸ì‹ (í•œêµ­ì–´/ì˜ì–´)
- ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ (RAG)
- ìŒì„± í•©ì„±

## ë¬¸ì„œ ì¶”ê°€
documents í´ë”ì— .txt ë˜ëŠ” .md íŒŒì¼ì„ ì¶”ê°€í•˜ë©´
AIê°€ í•´ë‹¹ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.
''', encoding='utf-8')
        
        logger.info("Created sample document")
        self._load_documents()
    
    def search(self, query: str, top_k: int = 3) -> list:
        """ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
        if not self.documents or self.embeddings is None:
            return []
        
        query_emb = self.embedding_model.encode([query])[0]
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        similarities = np.dot(self.embeddings, query_emb) / (
            np.linalg.norm(self.embeddings, axis=1) * np.linalg.norm(query_emb)
        )
        
        top_idx = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        for idx in top_idx:
            if similarities[idx] > 0.3:  # ì„ê³„ê°’
                results.append({
                    'content': self.documents[idx]['content'],
                    'source': self.documents[idx]['source'],
                    'score': float(similarities[idx])
                })
        
        return results
    
    def generate_response(self, query: str) -> str:
        """ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±"""
        import requests
        
        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        relevant_docs = self.search(query)
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = ""
        if relevant_docs:
            context = "\n\n".join([
                f"[{d['source']}]\n{d['content']}"
                for d in relevant_docs
            ])
            logger.info(f"Found {len(relevant_docs)} relevant documents")
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        if context:
            prompt = f"""ë‹¤ìŒ ì°¸ê³ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ 2-3ë¬¸ì¥ìœ¼ë¡œ ì§§ê³  ëª…í™•í•˜ê²Œ í•´ì£¼ì„¸ìš”.

ì°¸ê³ ìë£Œ:
{context}

ì§ˆë¬¸: {query}

ë‹µë³€:"""
        else:
            prompt = f"""ì§ˆë¬¸ì— 2-3ë¬¸ì¥ìœ¼ë¡œ ì§§ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {query}

ë‹µë³€:"""
        
        # Ollama í˜¸ì¶œ
        try:
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "num_predict": 150
                    }
                },
                timeout=60
            )
            
            if response.status_code == 200:
                answer = response.json().get('response', '').strip()
                logger.info(f"LLM Response: '{answer[:100]}...'")
                return answer
            else:
                logger.error(f"Ollama error: {response.status_code}")
                return "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ”ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                
        except requests.exceptions.ConnectionError:
            logger.error("Cannot connect to Ollama")
            return "AI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
        except Exception as e:
            logger.error(f"Ollama error: {e}")
            return "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# =====================================
# ğŸ”§ ì „ì—­ ê°ì²´
# =====================================
stt: SpeechRecognizer = None
tts: SpeechSynthesizer = None
rag: RAGEngine = None

# =====================================
# ğŸŒ API ì—”ë“œí¬ì¸íŠ¸
# =====================================

@app.route('/voice', methods=['POST'])
def process_voice():
    """ìŒì„± ì²˜ë¦¬ ë©”ì¸ API"""
    start_time = time.time()
    
    try:
        # 1. ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹ 
        audio_data = request.data
        if not audio_data:
            return jsonify({'error': 'No audio data'}), 400
        
        logger.info(f"Received {len(audio_data)} bytes")
        
        # 2. WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        wav_data = raw_to_wav(audio_data)
        
        # 3. ìŒì„± ì¸ì‹
        text = stt.transcribe(wav_data)
        if not text:
            text = "ì¸ì‹ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"
        
        # 4. AI ì‘ë‹µ ìƒì„±
        response_text = rag.generate_response(text)
        
        # 5. ìŒì„± í•©ì„±
        response_audio = tts.synthesize(response_text)
        
        elapsed = time.time() - start_time
        logger.info(f"Total processing time: {elapsed:.2f}s")
        
        # 6. WAV ì‘ë‹µ
        return send_file(
            io.BytesIO(response_audio),
            mimetype='audio/wav'
        )
        
    except Exception as e:
        logger.error(f"Error: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/text', methods=['POST'])
def process_text():
    """í…ìŠ¤íŠ¸ API (í…ŒìŠ¤íŠ¸ìš©)"""
    try:
        data = request.json
        text = data.get('text', '')
        
        if not text:
            return jsonify({'error': 'No text'}), 400
        
        response = rag.generate_response(text)
        
        return jsonify({
            'question': text,
            'answer': response
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/health', methods=['GET'])
def health():
    """ìƒíƒœ í™•ì¸"""
    return jsonify({
        'status': 'healthy',
        'stt': stt is not None,
        'tts': tts is not None,
        'rag': rag is not None,
        'documents': len(rag.documents) if rag else 0
    })


@app.route('/documents', methods=['GET'])
def list_documents():
    """ë¬¸ì„œ ëª©ë¡"""
    if not rag:
        return jsonify({'documents': []})
    
    sources = list(set(d['source'] for d in rag.documents))
    return jsonify({'documents': sources})


@app.route('/documents/reload', methods=['POST'])
def reload_documents():
    """ë¬¸ì„œ ë‹¤ì‹œ ë¡œë“œ"""
    try:
        rag._load_documents()
        return jsonify({
            'status': 'success',
            'documents': len(rag.documents)
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# =====================================
# ğŸ”§ ìœ í‹¸ë¦¬í‹°
# =====================================

def raw_to_wav(raw_data: bytes) -> bytes:
    """Raw PCM â†’ WAV ë³€í™˜"""
    wav_buffer = io.BytesIO()
    
    with wave.open(wav_buffer, 'wb') as wav:
        wav.setnchannels(Config.CHANNELS)
        wav.setsampwidth(Config.SAMPLE_WIDTH)
        wav.setframerate(Config.SAMPLE_RATE)
        wav.writeframes(raw_data)
    
    wav_buffer.seek(0)
    return wav_buffer.read()


def initialize():
    """ì„œë²„ ì´ˆê¸°í™”"""
    global stt, tts, rag
    
    logger.info("="*50)
    logger.info("  Voice RAG Server Initializing...")
    logger.info("="*50)
    
    # STT
    logger.info("\n[1/3] Loading Speech Recognition...")
    stt = SpeechRecognizer(Config.WHISPER_MODEL)
    
    # TTS  
    logger.info("\n[2/3] Loading Speech Synthesis...")
    tts = SpeechSynthesizer(Config.TTS_LANGUAGE)
    
    # RAG
    logger.info("\n[3/3] Loading RAG Engine...")
    rag = RAGEngine(Config.DOCUMENTS_DIR, Config.OLLAMA_MODEL, Config.OLLAMA_URL)
    
    logger.info("\n" + "="*50)
    logger.info("  Server Ready!")
    logger.info("="*50)

# =====================================
# ğŸš€ ë©”ì¸
# =====================================
if __name__ == '__main__':
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     ğŸ¤ Voice RAG Server                   â•‘
â•‘     for ESP32-S3 Nano                     â•‘
â•‘     Raspberry Pi 5                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    initialize()
    
    print(f"\nğŸŒ Server: http://0.0.0.0:{Config.PORT}")
    print(f"ğŸ“ Set this IP in ESP32 config.h")
    print(f"ğŸ›‘ Stop: Ctrl+C\n")
    
    app.run(
        host=Config.HOST,
        port=Config.PORT,
        debug=False,
        threaded=True
    )
